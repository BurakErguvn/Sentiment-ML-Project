{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn import linear_model, preprocessing,model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tensorflow \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reading and Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence you want to learn whether it is positive or negative.\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter the sentence you want to learn whether it is positive or negative.\")#Data can be extracted from any source, database or a csv file, but I preferred this :D\n",
    "text= input()\n",
    "text_series = pd.Series(text)\n",
    "text_series= text_series.apply(lambda x: \" \".join(x.lower() for x in x.split())) #conversion of words to lowercase\n",
    "text_series = text_series.str.replace(\"[^\\w\\s]\",\"\",regex= True) #deleting punctuation marks\n",
    "text_series = text_series.str.replace(\"\\d\",\"\",regex=True) #deleting numbers\n",
    "sw = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "      'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', \n",
    "      'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', \n",
    "      'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', \n",
    "      'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', \n",
    "      'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', \n",
    "      'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain']\n",
    "text_series = text_series.apply(lambda x: \" \".join(x for x in x.split() if x not in sw)) #deleting stopwords\n",
    "text = text_series.to_string(index= False)\n",
    "words = text.split()\n",
    "if len(words) < 20:\n",
    "    delete = pd.Series(\" \".join(text_series).split()).value_counts()[-3:]\n",
    "    text_series = text_series.apply(lambda x: \" \".join(x for x in x.split() if x not in delete)) #deleting rare wordsdeleting rare words\n",
    "else:\n",
    "    delete = pd.Series(\" \".join(text_series).split()).value_counts()[-6:]\n",
    "    text_series = text_series.apply(lambda x: \" \".join(x for x in x.split() if x not in delete)) #deleting rare wordsdeleting rare words\n",
    "text_series= text_series.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))#lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence is positive\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"org_opmin.csv\",usecols=[\"Text\",\"Label\"])\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(df[\"Text\"],df[\"Label\"], random_state= 42)\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_x)\n",
    "x_train_count = vectorizer.transform(train_x) #This process creates a vector for each word and applies it to each line.\n",
    "loj_model = linear_model.LogisticRegression(solver=\"liblinear\",C=1,intercept_scaling=0.1,max_iter=100,penalty=\"l2\",tol=1)\n",
    "loj_model = loj_model.fit(x_train_count,train_y)\n",
    "feedback = loj_model.predict(vectorizer.transform(text_series))\n",
    "feedback = np.array2string(feedback)\n",
    "if feedback == \"[0]\":\n",
    "    print(\"This sentence is negative\")\n",
    "else:\n",
    "    print(\"This sentence is positive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
