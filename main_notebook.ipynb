{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn import linear_model, preprocessing,model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tensorflow \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reading and Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence you want to learn whether it is positive or negative.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>place every time order drive thru make park wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  place every time order drive thru make park wa..."
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Enter the sentence you want to learn whether it is positive or negative.\")#Data can be extracted from any source, database or a csv file, but I preferred this :D\n",
    "text_orginal= input()\n",
    "text_df= pd.DataFrame([text_orginal],columns=[\"Text\"])\n",
    "text_series= text_df[\"Text\"].apply(lambda x: \" \".join(x.lower() for x in x.split())) #conversion of words to lowercase\n",
    "text_series = text_series.str.replace(\"[^\\w\\s]\",\"\",regex= True) #deleting punctuation marks\n",
    "text_series = text_series.str.replace(\"\\d\",\"\",regex=True) #deleting numbers\n",
    "text_df= pd.DataFrame(text_series,columns=[\"Text\"])\n",
    "sw = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "      'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', \n",
    "      'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', \n",
    "      'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', \n",
    "      'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', \n",
    "      'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', \n",
    "      'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain']\n",
    "text_series = text_df[\"Text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw)) #deleting stopwords\n",
    "text_df= pd.DataFrame(text_series,columns=[\"Text\"])\n",
    "text = text_series.to_string(index= False)\n",
    "words = text.split()\n",
    "if len(words) < 20:\n",
    "    delete = pd.Series(\" \".join(text_df[\"Text\"]).split()).value_counts()[-3:]\n",
    "    text_series = text_df[\"Text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in delete)) #deleting rare wordsdeleting rare words\n",
    "else:\n",
    "    delete = pd.Series(\" \".join(text_df[\"Text\"]).split()).value_counts()[-6:]\n",
    "    text_series = text_df[\"Text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in delete)) #deleting rare wordsdeleting rare words\n",
    "text_df= pd.DataFrame(text_series,columns=[\"Text\"])\n",
    "text_series= text_df[\"Text\"].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))#lemmatization\n",
    "text_df= pd.DataFrame(text_series,columns=[\"Text\"])\n",
    "text_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence is negative\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"org_opmin.csv\",usecols=[\"Text\",\"Label\"])\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(df[\"Text\"],df[\"Label\"], random_state= 42)\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_x)\n",
    "x_train_count = vectorizer.transform(train_x) #This process creates a vector for each word and applies it to each line.\n",
    "loj_model = linear_model.LogisticRegression(solver=\"liblinear\",C=1,intercept_scaling=0.1,max_iter=100,penalty=\"l2\",tol=1)\n",
    "loj_model = loj_model.fit(x_train_count,train_y)\n",
    "feedback = loj_model.predict(vectorizer.transform(text_series))\n",
    "feedback = np.array2string(feedback)\n",
    "if feedback == \"[0]\":\n",
    "    print(\"This sentence is negative\")\n",
    "    feedback = \"Negative\"\n",
    "else:\n",
    "    print(\"This sentence is positive\")\n",
    "    feedback = \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did I guess correctly? Y/N\n",
      "Do you want to save the data? Y/N\n"
     ]
    }
   ],
   "source": [
    "print(\"Did I guess correctly? Y/N\")\n",
    "conf2 = input()\n",
    "print(\"Do you want to save the data? Y/N\")\n",
    "conf1 = input()\n",
    "if conf1 == \"Y\":\n",
    "    if conf2 == \"Y\":\n",
    "        new_df = pd.read_csv(\"opmin2.csv\",usecols=[\"Text\",\"Label\"])\n",
    "        new_data = {\"Text\": text_orginal, \"Label\": feedback}\n",
    "        new_df.loc[len(new_df)] = new_data\n",
    "        new_df.to_csv(\"opmin2.csv\")\n",
    "        new_org_df = pd.read_csv(\"org_opmin2.csv\",usecols=[\"Text\",\"Label\"])\n",
    "        label_df = pd.DataFrame([feedback],columns=[\"Label\"])\n",
    "        df_df= pd.concat([text_df,label_df],ignore_index= True,axis=1,)\n",
    "        df_df.columns =[\"Text\",\"Label\"]\n",
    "        new_org_df = pd.concat([new_org_df,df_df],ignore_index= True,axis=0)\n",
    "        new_org_df.to_csv(\"org_opmin2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>everything top much trouble decor throughout l...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place every time order drive thru make park wa...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0  everything top much trouble decor throughout l...  Positive\n",
       "1  place every time order drive thru make park wa...  Negative"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_org_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mleft\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DataFrame | Series'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mright\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DataFrame | Series'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mhow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'MergeHow'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'inner'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mon\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'IndexLabel | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mleft_on\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'IndexLabel | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mright_on\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'IndexLabel | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mleft_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mright_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msuffixes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Suffixes'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'_x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mindicator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Merge DataFrame or named Series objects with a database-style join.\n",
      "\n",
      "A named Series object is treated as a DataFrame with a single named column.\n",
      "\n",
      "The join is done on columns or indexes. If joining columns on\n",
      "columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      "on indexes or indexes on a column or columns, the index will be passed on.\n",
      "When performing a cross merge, no column specifications to merge on are\n",
      "allowed.\n",
      "\n",
      ".. warning::\n",
      "\n",
      "    If both key columns contain rows where the key is a null value, those\n",
      "    rows will be matched against each other. This is different from usual SQL\n",
      "    join behaviour and can lead to unexpected results.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "left : DataFrame or named Series\n",
      "right : DataFrame or named Series\n",
      "    Object to merge with.\n",
      "how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      "    Type of merge to be performed.\n",
      "\n",
      "    * left: use only keys from left frame, similar to a SQL left outer join;\n",
      "      preserve key order.\n",
      "    * right: use only keys from right frame, similar to a SQL right outer join;\n",
      "      preserve key order.\n",
      "    * outer: use union of keys from both frames, similar to a SQL full outer\n",
      "      join; sort keys lexicographically.\n",
      "    * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      "      join; preserve the order of the left keys.\n",
      "    * cross: creates the cartesian product from both frames, preserves the order\n",
      "      of the left keys.\n",
      "\n",
      "      .. versionadded:: 1.2.0\n",
      "\n",
      "on : label or list\n",
      "    Column or index level names to join on. These must be found in both\n",
      "    DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      "    to the intersection of the columns in both DataFrames.\n",
      "left_on : label or list, or array-like\n",
      "    Column or index level names to join on in the left DataFrame. Can also\n",
      "    be an array or list of arrays of the length of the left DataFrame.\n",
      "    These arrays are treated as if they are columns.\n",
      "right_on : label or list, or array-like\n",
      "    Column or index level names to join on in the right DataFrame. Can also\n",
      "    be an array or list of arrays of the length of the right DataFrame.\n",
      "    These arrays are treated as if they are columns.\n",
      "left_index : bool, default False\n",
      "    Use the index from the left DataFrame as the join key(s). If it is a\n",
      "    MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "    or a number of columns) must match the number of levels.\n",
      "right_index : bool, default False\n",
      "    Use the index from the right DataFrame as the join key. Same caveats as\n",
      "    left_index.\n",
      "sort : bool, default False\n",
      "    Sort the join keys lexicographically in the result DataFrame. If False,\n",
      "    the order of the join keys depends on the join type (how keyword).\n",
      "suffixes : list-like, default is (\"_x\", \"_y\")\n",
      "    A length-2 sequence where each element is optionally a string\n",
      "    indicating the suffix to add to overlapping column names in\n",
      "    `left` and `right` respectively. Pass a value of `None` instead\n",
      "    of a string to indicate that the column name from `left` or\n",
      "    `right` should be left as-is, with no suffix. At least one of the\n",
      "    values must not be None.\n",
      "copy : bool, default True\n",
      "    If False, avoid copy if possible.\n",
      "indicator : bool or str, default False\n",
      "    If True, adds a column to the output DataFrame called \"_merge\" with\n",
      "    information on the source of each row. The column can be given a different\n",
      "    name by providing a string argument. The column will have a Categorical\n",
      "    type with the value of \"left_only\" for observations whose merge key only\n",
      "    appears in the left DataFrame, \"right_only\" for observations\n",
      "    whose merge key only appears in the right DataFrame, and \"both\"\n",
      "    if the observation's merge key is found in both DataFrames.\n",
      "\n",
      "validate : str, optional\n",
      "    If specified, checks if merge is of specified type.\n",
      "\n",
      "    * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      "      left and right datasets.\n",
      "    * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      "      dataset.\n",
      "    * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      "      dataset.\n",
      "    * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame\n",
      "    A DataFrame of the two merged objects.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "merge_ordered : Merge with optional filling/interpolation.\n",
      "merge_asof : Merge on nearest keys.\n",
      "DataFrame.join : Similar method using indices.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Support for specifying index levels as the `on`, `left_on`, and\n",
      "`right_on` parameters was added in version 0.23.0\n",
      "Support for merging named Series objects was added in version 0.24.0\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "...                     'value': [1, 2, 3, 5]})\n",
      ">>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "...                     'value': [5, 6, 7, 8]})\n",
      ">>> df1\n",
      "    lkey value\n",
      "0   foo      1\n",
      "1   bar      2\n",
      "2   baz      3\n",
      "3   foo      5\n",
      ">>> df2\n",
      "    rkey value\n",
      "0   foo      5\n",
      "1   bar      6\n",
      "2   baz      7\n",
      "3   foo      8\n",
      "\n",
      "Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      "the default suffixes, _x and _y, appended.\n",
      "\n",
      ">>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      "  lkey  value_x rkey  value_y\n",
      "0  foo        1  foo        5\n",
      "1  foo        1  foo        8\n",
      "2  foo        5  foo        5\n",
      "3  foo        5  foo        8\n",
      "4  bar        2  bar        6\n",
      "5  baz        3  baz        7\n",
      "\n",
      "Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      "appended to any overlapping columns.\n",
      "\n",
      ">>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      "...           suffixes=('_left', '_right'))\n",
      "  lkey  value_left rkey  value_right\n",
      "0  foo           1  foo            5\n",
      "1  foo           1  foo            8\n",
      "2  foo           5  foo            5\n",
      "3  foo           5  foo            8\n",
      "4  bar           2  bar            6\n",
      "5  baz           3  baz            7\n",
      "\n",
      "Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      "any overlapping columns.\n",
      "\n",
      ">>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      "Traceback (most recent call last):\n",
      "...\n",
      "ValueError: columns overlap but no suffix specified:\n",
      "    Index(['value'], dtype='object')\n",
      "\n",
      ">>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      ">>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      ">>> df1\n",
      "      a  b\n",
      "0   foo  1\n",
      "1   bar  2\n",
      ">>> df2\n",
      "      a  c\n",
      "0   foo  3\n",
      "1   baz  4\n",
      "\n",
      ">>> df1.merge(df2, how='inner', on='a')\n",
      "      a  b  c\n",
      "0   foo  1  3\n",
      "\n",
      ">>> df1.merge(df2, how='left', on='a')\n",
      "      a  b  c\n",
      "0   foo  1  3.0\n",
      "1   bar  2  NaN\n",
      "\n",
      ">>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      ">>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      ">>> df1\n",
      "    left\n",
      "0   foo\n",
      "1   bar\n",
      ">>> df2\n",
      "    right\n",
      "0   7\n",
      "1   8\n",
      "\n",
      ">>> df1.merge(df2, how='cross')\n",
      "   left  right\n",
      "0   foo      7\n",
      "1   foo      8\n",
      "2   bar      7\n",
      "3   bar      8\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\burak\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages\\pandas\\core\\reshape\\merge.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?pd.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
